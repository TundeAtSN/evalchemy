[project]
name = "evalchemy"
version = "0.1.0"
description = "Evalchemy Evaluation Framework"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "accelerate>=1.3.0",
    "aiofiles>=23.2.1",
    "aiohttp[speedups]>=3.11.12",
    "anthropic>=0.42.0",
    "appdirs>=1.4.4",
    "backoff>=2.2.1",
    "bespokelabs-curator>=0.1.16.0",
    "bitsandbytes>=0.45.2 ; sys_platform == 'linux'",
    "black>=25.1.0",
    "bs4>=0.0.2",
    "codebleu>=0.7.0",
    "cohere>=5.13.12",
    "dashscope>=1.22.1",
    "datasets>=3.2.0",
    "evaluate>=0.4.3",
    "faiss-cpu>=1.10.0",
    "fastavro>=1.10.0",
    "fasttext-wheel>=0.9.2",
    "fire>=0.7.0",
    "fschat",
    "fsspec>=2024.9.0",
    "fuzzywuzzy>=0.18.0",
    "gcsfs>=2024.9.0.post1",
    "google-auth>=2.38.0",
    "google-cloud-aiplatform>=1.80.0",
    "google-generativeai>=0.8.4",
    "hf-transfer>=0.1.9",
    "hjson>=3.1.0",
    "huggingface-hub[cli]>=0.28.1",
    "immutabledict>=4.2.1",
    "jsonpickle>=4.0.1",
    "langdetect>=1.0.9",
    "lm-eval[vllm] ; sys_platform == 'linux'",
    "lm-eval ; sys_platform == 'darwin'",
    "loguru>=0.7.3",
    "mistralai>=1.5.0",
    "msgpack>=1.1.0",
    "mypy-extensions>=1.0.0",
    "nltk>=3.9.1",
    "openai>=1.62.0",
    "optimum==1.12.0",
    "peft>=0.14.0",
    "pqdm>=0.2.0",
    "prettytable>=3.14.0",
    "protobuf>=5.29.3",
    "psycopg2-binary>=2.9.10",
    "psycopg[binary]>=3.2.4",
    "py-cpuinfo>=9.0.0",
    "pyext",
    "python-box>=7.3.2",
    "python-levenshtein>=0.26.1",
    "ray[default]>=2.42.1",
    "reka-api>=3.2.0",
    "sacrebleu>=2.5.1",
    "sagemaker>=2.239.0",
    "sentence-transformers>=3.4.1",
    "sentencepiece>=0.2.0",
    "shortuuid>=1.0.13",
    "sqlalchemy>=2.0.38",
    "sqlitedict>=2.1.0",
    "tempdir>=0.7.1",
    "tensorboard>=2.19.0",
    "together>=1.4.0",
    "tree-sitter>=0.22.3",
    "tree-sitter-java>=0.23.5",
    "tree-sitter-languages>=1.10.2",
    "tree-sitter-python>=0.23.6",
    "trl>=0.14.0",
    "wandb>=0.19.6",
    "websocket>=0.2.1",
    "wget>=3.2",
    "alpaca-eval",
]

[tool.uv]
package = true

[tool.uv.sources]
pyext = { git = "https://github.com/penfever/PyExt" }
lm-eval = { git = "https://github.com/EtashGuha/lm-evaluation-harness", rev = "etashg/tokenize_fix" }
fschat = { path = "eval/chat_benchmarks/MTBench" }
alpaca-eval = { path = "eval/chat_benchmarks/alpaca_eval" }

[tool.setuptools.packages.find]
include = ["eval", "database"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]

[tool.black]
line-length = 120

[tool.isort]
profile = "black"
multi_line_output = 3

[dependency-groups]
dev = [
    "isort>=6.0.0",
    "pre-commit>=4.1.0",
    "pytest>=8.3.4",
]
